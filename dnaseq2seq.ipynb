{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "950d53c1-1bb9-44fd-be96-e014a1ed9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import copy\n",
    "import pysam\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "9de3bc59-3086-49f9-b5f8-5dfcaa4c9238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c529cc2e-8196-47fa-a8f2-bc439123d6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if hasattr(torch, 'cuda') and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c58880-512c-4400-bbfd-73770ed91140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "e79bf2da-d1c4-4b32-88bb-028fcfeece9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STOP_TOKEN_INDEX = 4\n",
    "\n",
    "INDEX_TO_BASE = [\n",
    "    'A', 'C', 'G', 'T'\n",
    "]\n",
    "\n",
    "def base_index(base):\n",
    "    if base=='A':\n",
    "        return 0\n",
    "    elif base=='C':\n",
    "        return 1\n",
    "    elif base=='G':\n",
    "        return 2\n",
    "    elif base=='T':\n",
    "        return 3\n",
    "    raise ValueError(\"Expected [ACTG]\")\n",
    "    \n",
    "def update_from_base(base, tensor):\n",
    "    if base=='A':\n",
    "        tensor[0] = 1\n",
    "    elif base=='C':\n",
    "        tensor[1] = 1\n",
    "    elif base=='G':\n",
    "        tensor[2] = 1\n",
    "    elif base=='T':\n",
    "        tensor[3] = 1\n",
    "    elif base=='N':\n",
    "        tensor[0:3] = 0.25\n",
    "    elif base=='-':\n",
    "        tensor[0:3] = 0.0\n",
    "    return tensor\n",
    "\n",
    "def encode_basecall(base, qual, cigop):\n",
    "    ebc = torch.zeros(6)\n",
    "    ebc = update_from_base(base, ebc)\n",
    "    ebc[4] = qual / 100 - 0.5\n",
    "    ebc[5] = cigop\n",
    "    return ebc\n",
    "\n",
    "def encode_cigop(readpos, refpos):\n",
    "    if readpos == refpos:\n",
    "        return 0\n",
    "    elif readpos is None:\n",
    "        return -1\n",
    "    elif refpos is None:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def variantrec_to_tensor(rec):\n",
    "    seq = []\n",
    "    for readpos, refpos in rec.get_aligned_pairs():\n",
    "        if readpos is not None and refpos is not None:\n",
    "            seq.append(encode_basecall(rec.query_sequence[readpos], rec.query_qualities[readpos], encode_cigop(readpos, refpos)))\n",
    "        elif readpos is None and refpos is not None:\n",
    "            seq.append(encode_basecall('-', 50, encode_cigop(readpos, refpos)))  # Deletion\n",
    "        elif readpos is not None and refpos is None:\n",
    "            seq.append(encode_basecall(rec.query_sequence[readpos], rec.query_qualities[readpos], encode_cigop(readpos, refpos)))  # Insertion\n",
    "        \n",
    "    return torch.vstack(seq)\n",
    "\n",
    "\n",
    "def string_to_tensor(bases):\n",
    "    return torch.vstack([encode_basecall(b, 50, 0) for b in bases])\n",
    "\n",
    "\n",
    "def target_string_to_tensor(bases, include_stop=True):\n",
    "    \"\"\"\n",
    "    The target version doesn't include the qual or cigop features\n",
    "    \"\"\"\n",
    "    result = torch.tensor([base_index(b) for b in bases]).long()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "8faf8903-8eaa-47b5-a548-d21f13910a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_zeros(pre, data, post):\n",
    "    if pre:\n",
    "        prepad = torch.zeros(pre, data.shape[-1])\n",
    "        data = torch.cat((prepad, data))\n",
    "    if post:\n",
    "        postpad = torch.zeros(post, data.shape[-1])\n",
    "        data = torch.cat((data, postpad))\n",
    "    return data\n",
    "    \n",
    "def tensors_from_seq(refseq, numreads, readlen, error_rate=0.0, align_to_ref=True):\n",
    "    seqs = []\n",
    "    for i in range(numreads):\n",
    "        startpos = random.randint(0, len(refseq) - readlen)\n",
    "        if align_to_ref:\n",
    "            seqs.append(\n",
    "                pad_zeros(startpos, \n",
    "                      string_to_tensor(mutate_seq(refseq[startpos:startpos+readlen], error_rate)),\n",
    "                      len(refseq) - startpos - readlen)\n",
    "            )\n",
    "        else:\n",
    "            seqs.append(\n",
    "                string_to_tensor(mutate_seq(refseq[startpos:startpos+readlen], error_rate)),\n",
    "            )\n",
    "    return torch.stack(seqs)\n",
    "\n",
    "\n",
    "def mutate_seq(seq, error_rate):\n",
    "    output = []\n",
    "    for b in seq:\n",
    "        if np.random.rand() < error_rate:\n",
    "            c = random.choice('ACTG')\n",
    "            while c == b:\n",
    "                c = random.choice('ACTG')\n",
    "        else:\n",
    "            c = b\n",
    "        output.append(c)\n",
    "    return \"\".join(output)\n",
    "                \n",
    "\n",
    "def random_bases(n):\n",
    "    return \"\".join(random.choices(\"ACTG\", k=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "7971dd5a-0c2c-4df9-9acc-e0aab1708995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27023285 - 27023435\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 0, 4 \ttorch.Size([150, 6])\n",
      "146M 1, 3 \ttorch.Size([150, 6])\n",
      "146M 1, 3 \ttorch.Size([150, 6])\n",
      "146M 1, 3 \ttorch.Size([150, 6])\n",
      "146M 1, 3 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 2, 2 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "143M3S 3, 4 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 3, 1 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n",
      "146M 4, 0 \ttorch.Size([150, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 150, 6])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_and_tensorize_reads(reads):\n",
    "    minref = min(r.reference_start for r in reads)\n",
    "    maxref = max(r.reference_start + r.query_length for r in reads)\n",
    "    reflen = maxref - minref\n",
    "    print(f\"{minref} - {maxref}\")\n",
    "    tensors = [\n",
    "        pad_zeros(r.reference_start - minref, variantrec_to_tensor(r), maxref - (r.reference_start + r.query_length))\n",
    "        for r in reads\n",
    "    ]\n",
    "    for r, t in zip(reads, tensors):\n",
    "        print(f\"{r.cigarstring} {r.reference_start - minref}, {maxref - r.reference_end} \\t{t.shape}\")\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "pad_and_tensorize_reads(reads).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "bfa5fb29-b096-4d0f-a688-9579643447bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_pileup(bam, chrom, start, maxnumreads):\n",
    "    bamit = bam.fetch(chrom, start)\n",
    "    reads = []\n",
    "    num_reads = 50\n",
    "    while len(reads) < num_reads:\n",
    "        reads.append(next(bamit))\n",
    "    return pad_and_tensorize_reads(reads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d195ce4a-cc9c-47db-8c35-a010c91e4539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27023255 - 27023404\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "121M3D25M 0, 0 \ttorch.Size([152, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "121M3D25M 0, 0 \ttorch.Size([152, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 0, 3 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 1, 2 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 2, 1 \ttorch.Size([149, 6])\n",
      "146M 3, 0 \ttorch.Size([149, 6])\n",
      "146M 3, 0 \ttorch.Size([149, 6])\n",
      "146M 3, 0 \ttorch.Size([149, 6])\n",
      "146M 3, 0 \ttorch.Size([149, 6])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [149, 6] at entry 0 and [152, 6] at entry 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-400-72d546bf7762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_pileup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27023400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-390-49c688ce4251>\u001b[0m in \u001b[0;36mtensor_pileup\u001b[0;34m(bam, chrom, start, maxnumreads)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_reads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbamit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpad_and_tensorize_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-392-6e45289427d7>\u001b[0m in \u001b[0;36mpad_and_tensorize_reads\u001b[0;34m(reads)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{r.cigarstring} {r.reference_start - minref}, {maxref - r.reference_end} \\t{t.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpad_and_tensorize_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [149, 6] at entry 0 and [152, 6] at entry 3"
     ]
    }
   ],
   "source": [
    "tensor_pileup(bam, \"1\", 27023400, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "cf42d59b-f853-4461-af7d-5a1038297135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3, 2])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_string_to_tensor(\"ACTG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "c9dbfde0-8cc6-4297-a40a-14325b79019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bam = pysam.AlignmentFile(\"/home/brendan/Public/genomics/onccn_15_car641/bam/roi.bam\")\n",
    "bamit = bam.fetch(\"1\", 27022800)\n",
    "\n",
    "reads = []\n",
    "num_reads = 500\n",
    "while len(reads) < num_reads:\n",
    "    reads.append(next(bamit))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "82e19e48-be07-47ae-ae11-9868f21e11c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pysam.libcalignedsegment.AlignedSegment object at 0x7f6cd738ae20>, <pysam.libcalignedsegment.AlignedSegment object at 0x7f6cd7386f40>]\n"
     ]
    }
   ],
   "source": [
    "def get_read_by_name(bam, name):\n",
    "    results = []\n",
    "    for read in bam:\n",
    "        if read.query_name == name:\n",
    "            results.append(read)\n",
    "    return results\n",
    "readhits = get_read_by_name(reads, \"A00576:57:HCN2WDRXX:1:1115:28646:35070:CTGTG+ATCTC\")\n",
    "print(readhits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "173cda79-2c7e-46ce-b73a-1d968be088aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146, 6])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variantrec_to_tensor(read).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cc8ae-9e50-438c-8bf6-bdfb2922b2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "717b7c4b-7a84-47de-9156-b678c0c30e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27S28M2I89M\n"
     ]
    }
   ],
   "source": [
    "def iterate_cigar(rec):\n",
    "    cigtups = rec.cigartuples\n",
    "    bases = rec.query_sequence\n",
    "    quals = rec.query_qualities\n",
    "    cig_index = 0\n",
    "    n_bases_cigop = cigtups[cig_index][1]\n",
    "    cigop = cigtups[cig_index][0]\n",
    "    is_ref_consumed = cigop in {0,   2,    4, 5, 7} # 2 is deletion\n",
    "    is_seq_consumed = cigop in {0, 1,   3, 4, 5, 7} # 1 is insertion, 3 is 'ref skip'\n",
    "    base_index = 0\n",
    "    refstart = rec.query_alignment_start - (n_bases_cigop if cigop in {4,5} else 0)\n",
    "    refpos = refstart\n",
    "    while True:\n",
    "        reftok = refpos if is_ref_consumed else \"-\"\n",
    "        if is_seq_consumed:\n",
    "            base = bases[base_index]\n",
    "            qual = quals[base_index]\n",
    "            base_index += 1\n",
    "        else:\n",
    "            base = \"-\"\n",
    "        if is_ref_consumed:\n",
    "            refpos += 1\n",
    "    \n",
    "        print(f\"{base}\\t{reftok}\\t cig op: {cigop} num bases left in cig op: {n_bases_cigop}\")\n",
    "        encoded_cig = 0\n",
    "        if is_ref_consumed and is_seq_consumed:\n",
    "            encoded_cig = 0\n",
    "        elif is_ref_consumed and not is_seq_consumed:\n",
    "            encoded_cig = -1\n",
    "        else:\n",
    "            encoded_cig = 1\n",
    "        yield encode_basecall(base, qual, encoded_cig), is_ref_consumed\n",
    "        n_bases_cigop -= 1\n",
    "        if n_bases_cigop <= 0:\n",
    "            cig_index += 1\n",
    "            if cig_index >= len(cigtups):\n",
    "                break\n",
    "            n_bases_cigop = cigtups[cig_index][1]\n",
    "            cigop = cigtups[cig_index][0]\n",
    "            is_ref_consumed = cigop in {0, 2, 4, 5, 7}\n",
    "            is_seq_consumed = cigop in {0, 1, 3, 4, 5, 7}\n",
    "\n",
    "def rec_tensor_it(read, minref, maxref):\n",
    "    for i in range(read.reference_start - minref):\n",
    "        yield encode_basecall('-', 50, 0), True\n",
    "\n",
    "    try:\n",
    "        for t in iterate_cigar(read):\n",
    "            yield t \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    for i in range(maxref - read.reference_start - read.query_length):\n",
    "        yield encode_basecall('-', 50, 0), True\n",
    "        \n",
    "print(read.cigarstring)\n",
    "# for t in rec_tensor_it(read, read.reference_start-5, read.reference_start + read.query_length+5):\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fccfa-0f64-469c-a170-67ad08735919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def iterate_aligned_reads(reads):\n",
    "    EMPTY_TENSOR = encode_basecall('-', 50, 0)\n",
    "    minref = min(r.reference_start for r in reads)\n",
    "    maxref = max(r.reference_start + r.query_length for r in reads)\n",
    "    its = [rec_tensor_it(r, minref, maxref) for r in reads]\n",
    "    refpos = minref\n",
    "    pos_tensors = [next(it) for it in its]\n",
    "    \n",
    "    while refpos < maxref:\n",
    "        any_insertion = any(r[1] for r in pos_tensors)\n",
    "        thispos = []\n",
    "        while any_insertion:\n",
    "            for i, (it, pos_tensor) in enumerate(zip(its, pos_tensors)):\n",
    "                if ins:\n",
    "                    thispos.append(pos_tensor[0])\n",
    "                    pos_tensors[i] = next(it)\n",
    "                else:\n",
    "                    thispos.append(EMPTY_TENSOR)\n",
    "        \n",
    "            any_insertion = any(r[1] for r in pos_tensors)\n",
    "    \n",
    "        all_stacked = torch.stack(thispos)\n",
    "        refpos += 1\n",
    "        for i, (it, pos_tensor) in enumerate(zip(its, pos_tensors)):\n",
    "            thispos.append(pos_tensor[0])\n",
    "            pos_tensors[i] = next(it)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3831048-cb35-4a14-a661-92b62b7c4578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febae40-ad1e-4830-bccc-520c6967a8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a6177-5d1c-4752-a6a9-914b8ec5f438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d008c546-8488-4d90-9391-639601b9c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_batch(batchsize, seqlen, readsperbatch, readlength, error_rate=0):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    for i in range(batchsize):\n",
    "        seq = random_bases(seqlen)\n",
    "        reads = tensors_from_seq(seq, readsperbatch, readlength, error_rate, align_to_ref=True)\n",
    "        src.append(reads)\n",
    "        tgt.append(target_string_to_tensor(seq))\n",
    "    return torch.stack(src).transpose(1,2).to(device), torch.stack(tgt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3d314-c433-42a4-842f-6f840cca6201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa6c55-e066-4a84-9c94-0c9b7def8fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "9362d28d-f14a-4b16-add9-a3a22adc65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...ATGCTTGTAGCACTAC......\n",
      ".GAATGCTTGTAGTACT........\n",
      ".........GTAGCACTACGATGAT\n",
      "....TGCTTGTAGCACTACG.....\n",
      "....TGCTTGTAGCACTACG.....\n",
      ".....GCTTGTAGTACTACGA....\n",
      "..AATGCTTGTAGCACTA.......\n",
      ".....GCTTGTAGCACTACGA....\n",
      ".GAATGCTTGTAGCACT........\n",
      ".......TTGTAGCACTACGATG..\n",
      "TGAATGCTTGTAGCAC.........\n",
      ".....GCTTGTAGTACTACGA....\n",
      ".....GCTTGTAGCACTACGA....\n",
      ".GAATGCTTGTAGTACT........\n",
      "..AATGCTTGTAGTACTA.......\n",
      ".....GCTTGTAGTACTACGA....\n",
      "......CTTGTAGTACTACGAT...\n",
      "TGAATGCTTGTAGTAC.........\n",
      ".....GCTTGTAGCACTACGA....\n",
      "....TGCTTGTAGTACTACG.....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def make_het_snv_batch(batchsize, seqlen, readsperbatch, readlength, error_rate):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    for i in range(batchsize):\n",
    "        seq = random_bases(seqlen)\n",
    "        reads, altseq = make_het_snv(seq, readlength, readsperbatch, 0.5, error_rate)\n",
    "        src.append(reads)\n",
    "        \n",
    "        \n",
    "        alt_t = target_string_to_tensor(altseq)\n",
    "        seq_t = target_string_to_tensor(seq)\n",
    "        x = torch.stack((seq_t, alt_t))\n",
    "        tgt.append(x)\n",
    "    return torch.stack(src).transpose(1,2).to(device), torch.stack(tgt).to(device)\n",
    "    \n",
    "src, tgt = make_het_snv_batch(5, 25, 20, 16, 0)\n",
    "print(to_pileup(src[0, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "2ad67ac0-c02e-48a6-9fca-496a6c87e02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 30, 10, 6])"
      ]
     },
     "execution_count": 1015,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def stack_refalt_tensrs(refseq, altseq, readlength, totreads, vaf=0.5):\n",
    "    assert len(refseq) == len(altseq), f\"Sequences must be the same length (got {len(refseq)} and {len(altseq)})\"\n",
    "    num_altreads = stats.binom(totreads - 2, vaf).rvs(1)[0] + 1\n",
    "    reftensors = tensors_from_seq(refseq, totreads-num_altreads, readlength, error_rate)\n",
    "    alttensors = tensors_from_seq(altseq, num_altreads, readlength, error_rate)\n",
    "    combined = torch.cat([reftensors, alttensors])\n",
    "    idx = np.random.permutation(totreads)\n",
    "    combined[range(totreads)] = combined[idx]\n",
    "    return combined, altseq\n",
    "\n",
    "def make_het_snv(seq, readlength, totreads, vaf, error_rate):\n",
    "    snvpos = random.choice(range(max(0, len(seq) // 2 - 8), min(len(seq), len(seq) // 2 + 8)))\n",
    "    altseq = list(seq)\n",
    "    altseq[snvpos] = random.choice('ACTG')\n",
    "    while altseq[snvpos] == seq[snvpos]:\n",
    "        altseq[snvpos] = random.choice('ACTG')\n",
    "    altseq = \"\".join(altseq)\n",
    "    return stack_refalt_tensrs(seq, altseq, readlength, totreads, vaf)\n",
    "\n",
    "def make_het_del(seq, readlength, totreads, vaf=0.5):\n",
    "    del_len = random.choice(range(10))\n",
    "    delpos = random.choice(range(max(0, len(seq) // 2 - 8), min(len(seq) - del_len, len(seq) // 2 + 8)))\n",
    "    ls = list(seq)\n",
    "    for i in range(del_len):\n",
    "        del ls[delpos]\n",
    "    altseq = \"\".join(ls + [\"A\"] * del_len)\n",
    "    return stack_refalt_tensrs(seq, altseq, readlength, totreads, vaf)\n",
    "\n",
    "\n",
    "def make_het_ins(seq, readlength, totreads, vaf=0.5):\n",
    "    ins_len = random.choice(range(10)) + 1\n",
    "    inspos = random.choice(range(max(0, len(seq) // 2 - 8), min(len(seq) - ins_len, len(seq) // 2 + 8)))\n",
    "    altseq = \"\".join(seq[0:inspos]) + \"\".join(random.choices(\"ACTG\", k=ins_len)) + \"\".join(seq[inspos:-ins_len])\n",
    "    altseq = altseq[0:len(seq)]\n",
    "    return stack_refalt_tensrs(seq, altseq, readlength, totreads, vaf)\n",
    "    \n",
    "\n",
    "def make_het_ins_batch(batchsize, seqlen, readsperbatch, readlength, error_rate):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    for i in range(batchsize):\n",
    "        seq = [b for b in random_bases(seqlen)]\n",
    "        reads, altseq = make_het_ins(seq, readlength, readsperbatch, vaf=0.5)\n",
    "        src.append(reads)\n",
    "        alt_t = target_string_to_tensor(altseq)\n",
    "        seq_t = target_string_to_tensor(seq)\n",
    "        x = torch.stack((seq_t, alt_t))\n",
    "        tgt.append(x)\n",
    "    return torch.stack(src).transpose(1,2).to(device), torch.stack(tgt).to(device)\n",
    "\n",
    "\n",
    "\n",
    "def make_het_del_batch(batchsize, seqlen, readsperbatch, readlength, error_rate):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    for i in range(batchsize):\n",
    "        seq = [b for b in random_bases(seqlen)]\n",
    "        reads, altseq = make_het_del(seq, readlength, readsperbatch, vaf=0.5)\n",
    "        src.append(reads)\n",
    "        alt_t = target_string_to_tensor(altseq)\n",
    "        seq_t = target_string_to_tensor(seq)\n",
    "        x = torch.stack((seq_t, alt_t))\n",
    "        tgt.append(x)\n",
    "    return torch.stack(src).transpose(1,2).to(device), torch.stack(tgt).to(device)\n",
    "    \n",
    "    \n",
    "\n",
    "# reads, seq = make_het_del([b for b in random_bases(20)], 15, 10)\n",
    "src, tgt = make_het_ins_batch(5, 30, 10, 20, error_rate=0)\n",
    "# print(to_pileup(src[0, :, :, :]))\n",
    "# # src, tgt = make_het_ins(\"AAAAAAAAAAAAAAA\", 8, 10)\n",
    "# # print(to_pileup(src[:, :, :].transpose(0,1)))\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "d6ecf73a-6f2e-411f-b274-39f138cff0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([95, 30, 10, 6])"
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_mixed_batch(size, seqlen, readsperbatch, readlength, error_rate):\n",
    "    snv_w = 9 # Bigger values here equal less variance among sizes\n",
    "    del_w = 8\n",
    "    ins_w = 8\n",
    "    mix = np.random.dirichlet((snv_w, del_w, ins_w)) * size\n",
    "    snv_src, snv_tgt = make_het_snv_batch(int(mix[0]), seqlen, readsperbatch, readlength, error_rate)\n",
    "    del_src, del_tgt = make_het_del_batch(int(mix[1]), seqlen, readsperbatch, readlength, error_rate)\n",
    "    ins_src, ins_tgt = make_het_ins_batch(int(mix[1]), seqlen, readsperbatch, readlength, error_rate)\n",
    "    return torch.cat((snv_src, del_src, ins_src)), torch.cat((snv_tgt, del_tgt, ins_tgt))\n",
    "src, tgt = make_mixed_batch(100, 30, 10, 18, 0)\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "7dae452d-ffe9-493c-a54d-3e800164c190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........AATGGGCGAAATCGGGCCAC.\n",
      "AGCCGCATCAATGGGCGAAA..........\n",
      "......ATCAATGGGCGATCGGGCCA....\n",
      "....GCATCAATGGGCGATCGGGC......\n",
      "AGCCGCATCAATGGGCGAAA..........\n",
      ".......TCAATGGGCGATCGGGCCAC...\n",
      "...CGCATCAATGGGCGATCGGG.......\n",
      ".GCCGCATCAATGGGCGAAAT.........\n",
      "........CAATGGGCGATCGGGCCACT..\n",
      "....GCATCAATGGGCGATCGGGC......\n",
      "Sorted:\n",
      "........CAATGGGCGATCGGGCCACT..\n",
      ".......TCAATGGGCGATCGGGCCAC...\n",
      "......ATCAATGGGCGATCGGGCCA....\n",
      "....GCATCAATGGGCGATCGGGC......\n",
      "....GCATCAATGGGCGATCGGGC......\n",
      "...CGCATCAATGGGCGATCGGG.......\n",
      "AGCCGCATCAATGGGCGAAA..........\n",
      ".........AATGGGCGAAATCGGGCCAC.\n",
      "AGCCGCATCAATGGGCGAAA..........\n",
      ".GCCGCATCAATGGGCGAAAT.........\n"
     ]
    }
   ],
   "source": [
    "def sort_by_ref(seq, reads):\n",
    "    results = []\n",
    "    for batch in range(reads.shape[0]):\n",
    "        w = reads[batch, :, :, 0:4].sum(dim=-1)\n",
    "        t = reads[batch, :, :, 0:4].argmax(dim=-1)\n",
    "        matchsum = (t == (seq[batch, 0, :].repeat(reads.shape[2], 1).transpose(0,1)*w).long()).sum(dim=0)\n",
    "        results.append(reads[batch, :, torch.argsort(matchsum), :])\n",
    "    return torch.stack(results)\n",
    "\n",
    "print(to_pileup(src[1,:,:,:]))\n",
    "srt_result = sort_by_ref(tgt, src)\n",
    "print(\"Sorted:\")\n",
    "print(to_pileup(srt_result[1, :, :, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "532c7192-1351-4995-85a0-4ffc12d41068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 3, 9, 0, 8, 7, 5, 6], device='cuda:0')"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(matchsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf813604-b57d-4437-b34a-6b2925b00771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f1872131-c77d-4802-8280-91ffc55b2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "08ba1c12-0da2-4b2a-8da9-f598d0a478f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TwoHapDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, out_dim)\n",
    "        self.fc3 = nn.Linear(128, out_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.fc1(x))\n",
    "        x1 = self.softmax(self.fc2(x))\n",
    "        x2 = self.softmax(self.fc3(x))\n",
    "        return x1, x2\n",
    "\n",
    "class VarTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, nhead=6, d_hid=256, n_encoder_layers=2, p_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = nhead * 12 # Was 24\n",
    "        self.fc1 = nn.Linear(in_dim, self.embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(self.embed_dim, p_dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(self.embed_dim, nhead, d_hid, p_dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_encoder_layers)\n",
    "        self.decoder = TwoHapDecoder(self.embed_dim, out_dim)\n",
    "        self.elu = torch.nn.ELU()\n",
    "    \n",
    "    def forward(self, src):\n",
    "        src = self.elu(self.fc1(src))\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f84aa-4ce6-48f1-a4f8-e9045017c9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "acdc9d0f-8be2-4510-bafc-adbe098fede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 30, 16, 6])\n",
      "torch.Size([5, 30, 4])\n",
      "torch.Size([5, 30, 4])\n"
     ]
    }
   ],
   "source": [
    "num_reads = 16\n",
    "feats_per_read = 6 \n",
    "ref_seq_length = 30\n",
    "read_length = 15\n",
    "src, tgt = make_het_snv_batch(5, seqlen=ref_seq_length, readsperbatch=num_reads, readlength=read_length, error_rate=0)\n",
    "print(src.shape)\n",
    "vt = VarTransformer(in_dim=num_reads * feats_per_read, out_dim=4).to(device)\n",
    "seq1, seq2 = vt(src.flatten(start_dim=2))\n",
    "print(seq1.shape)\n",
    "print(seq2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "b3f52481-0411-42ba-93aa-eb5d1b1d68a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 30])"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "ff1cc4f0-0384-4308-927d-d561deb59b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 30])"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_seq1 = tgt[:, 0, :]\n",
    "tgt_seq1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "3c897e71-902a-4618-9303-acd444c7dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_seq_length = 100\n",
    "read_length = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "f8d81794-f403-4929-8537-887f046b8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 150\n"
     ]
    }
   ],
   "source": [
    "num_reads = 25\n",
    "feats_per_read = 6 \n",
    "in_dim = num_reads * feats_per_read\n",
    "print(f\"Input dimension: {in_dim}\")\n",
    "model = VarTransformer(in_dim=in_dim, out_dim=4, nhead=5, d_hid=200, n_encoder_layers=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbc58e-5af3-4257-ab0e-d49e2f985e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653c37d-654a-47cc-9332-98bf07c3ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "b347262d-882f-4ad9-bd1f-096d0e5ff931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 96180 params\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad)} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "ffec4913-a67e-4516-9f46-550152b94795",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# mbloss = MatchingBasesLoss()\n",
    "# divloss = nn.KLDivLoss()\n",
    "lr = 0.001 # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "08823550-98d9-4e3c-9698-99c84eff3bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 loss: 2.2867 frac ref matching bases ref / alt: 0.9726 / 0.9743\n",
      "Step: 1 loss: 2.2918 frac ref matching bases ref / alt: 0.9645 / 0.9776\n",
      "Step: 2 loss: 2.2908 frac ref matching bases ref / alt: 0.9749 / 0.9766\n",
      "Step: 3 loss: 2.7463 frac ref matching bases ref / alt: 0.9744 / 0.9804\n",
      "Step: 4 loss: 2.7422 frac ref matching bases ref / alt: 0.9730 / 0.9819\n",
      "Step: 5 loss: 2.5140 frac ref matching bases ref / alt: 0.9708 / 0.9777\n",
      "Step: 6 loss: 2.2879 frac ref matching bases ref / alt: 0.9658 / 0.9808\n",
      "Step: 7 loss: 2.7435 frac ref matching bases ref / alt: 0.9721 / 0.9769\n",
      "Step: 8 loss: 2.2844 frac ref matching bases ref / alt: 0.9753 / 0.9782\n",
      "Step: 9 loss: 1.6007 frac ref matching bases ref / alt: 0.9653 / 0.9747\n",
      "Step: 10 loss: 2.0583 frac ref matching bases ref / alt: 0.9726 / 0.9794\n",
      "Step: 11 loss: 2.9750 frac ref matching bases ref / alt: 0.9766 / 0.9773\n",
      "Step: 12 loss: 2.2863 frac ref matching bases ref / alt: 0.9713 / 0.9776\n",
      "Step: 13 loss: 2.5132 frac ref matching bases ref / alt: 0.9778 / 0.9737\n",
      "Step: 14 loss: 2.2959 frac ref matching bases ref / alt: 0.9600 / 0.9360\n",
      "Step: 15 loss: 2.2886 frac ref matching bases ref / alt: 0.9775 / 0.9767\n",
      "Step: 16 loss: 2.7452 frac ref matching bases ref / alt: 0.9771 / 0.9621\n",
      "Step: 17 loss: 2.5147 frac ref matching bases ref / alt: 0.9805 / 0.9792\n",
      "Step: 18 loss: 2.5156 frac ref matching bases ref / alt: 0.9735 / 0.9788\n",
      "Step: 19 loss: 2.0568 frac ref matching bases ref / alt: 0.9744 / 0.9792\n",
      "Step: 20 loss: 2.7420 frac ref matching bases ref / alt: 0.9759 / 0.9788\n",
      "Step: 21 loss: 2.0557 frac ref matching bases ref / alt: 0.9726 / 0.9735\n",
      "Step: 22 loss: 2.7451 frac ref matching bases ref / alt: 0.9761 / 0.9768\n",
      "Step: 23 loss: 2.5113 frac ref matching bases ref / alt: 0.9763 / 0.9788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1052-5582156d62ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbatchsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_mixed_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsperbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     batchsrc, batchtgt = make_het_del_batch(batch_size * 10, seqlen=ref_seq_length, readsperbatch=num_reads, readlength=read_length, error_rate=0.02)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbatchoffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1017-8b59484d5769>\u001b[0m in \u001b[0;36mmake_mixed_batch\u001b[0;34m(size, seqlen, readsperbatch, readlength, error_rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mins_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirichlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnv_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msnv_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnv_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_het_snv_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsperbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdel_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_het_del_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsperbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mins_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_het_ins_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsperbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-799-22bbae485bae>\u001b[0m in \u001b[0;36mmake_het_snv_batch\u001b[0;34m(batchsize, seqlen, readsperbatch, readlength, error_rate)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_bases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_het_snv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsperbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1015-0db34ea58325>\u001b[0m in \u001b[0;36mmake_het_snv\u001b[0;34m(seq, readlength, totreads, vaf, error_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0maltseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnvpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ACTG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0maltseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack_refalt_tensrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_het_del\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1015-0db34ea58325>\u001b[0m in \u001b[0;36mstack_refalt_tensrs\u001b[0;34m(refseq, altseq, readlength, totreads, vaf)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack_refalt_tensrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Sequences must be the same length (got {len(refseq)} and {len(altseq)})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnum_altreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotreads\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mreftensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors_from_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotreads\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_altreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0malttensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors_from_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_altreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mfreeze\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \"\"\"\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dist, *args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# create a new instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updated_ctor_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, a, b, name, badvalue, moment_tol, values, inc, longname, shapes, extradoc, seed)\u001b[0m\n\u001b[1;32m   2943\u001b[0m                                   locscale_out='loc, 1')\n\u001b[1;32m   2944\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2945\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextradoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_construct_docstrings\u001b[0;34m(self, name, longname, extradoc)\u001b[0m\n\u001b[1;32m   3000\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3001\u001b[0m                 \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistdiscrete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3002\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocdict_discrete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m             \u001b[0;31m# discrete RV do not have the scale parameter, remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_construct_doc\u001b[0;34m(self, docdict, shapes_vals)\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%(shapes)s, \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoccer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 raise Exception(\"Unable to construct docstring for distribution \\\"%s\\\": %s\" %\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/_lib/doccer.py\u001b[0m in \u001b[0;36mdocformat\u001b[0;34m(docstring, docdict)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mindented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandtabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mnewlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = 50\n",
    "batch_size = 128\n",
    "error_rate = 0.02\n",
    "\n",
    "\n",
    "for step in range(steps):    \n",
    "    batchsrc, batchtgt = make_mixed_batch(batch_size * 10, seqlen=ref_seq_length, readsperbatch=num_reads, readlength=read_length, error_rate=error_rate)\n",
    "#     batchsrc, batchtgt = make_het_del_batch(batch_size * 10, seqlen=ref_seq_length, readsperbatch=num_reads, readlength=read_length, error_rate=0.02)\n",
    "    batchoffset = 0\n",
    "    epoch_loss_sum = 0\n",
    "    while batchoffset < batchsrc.shape[0]:\n",
    "        unsorted_src = batchsrc[batchoffset:batchoffset + batch_size, :, :, :]\n",
    "        tgt = batchtgt[batchoffset:batchoffset + batch_size, :, :]\n",
    "        src = sort_by_ref(tgt, unsorted_src)\n",
    "        batchoffset += batch_size\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_seq1 = tgt[:, 0, :]\n",
    "        tgt_seq2 = tgt[:, 1, :]\n",
    "\n",
    "        seq1preds, seq2preds = model(src.flatten(start_dim=2))\n",
    "\n",
    "        loss = criterion(seq1preds.flatten(start_dim=0, end_dim=1), tgt_seq1.flatten())\n",
    "        loss += 2*criterion(seq2preds.flatten(start_dim=0, end_dim=1), tgt_seq2.flatten())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            matches1 = (torch.argmax(seq1preds.flatten(start_dim=0, end_dim=1), dim=1) == tgt_seq1.flatten()).float().mean()\n",
    "            matches2 = (torch.argmax(seq2preds.flatten(start_dim=0, end_dim=1), dim=1) == tgt_seq2.flatten()).float().mean()\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        epoch_loss_sum += loss.detach().item()\n",
    "        \n",
    "        \n",
    "    print(f\"Step: {step} loss: {(epoch_loss_sum) / 10:.4f} frac ref matching bases ref / alt: {matches1.item():.4f} / {matches2.item():.4f}\" )\n",
    "    epoch_loss_sum = 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "d78d7031-0f25-484c-afa9-d9d2f0472e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7090, device='cuda:0')"
      ]
     },
     "execution_count": 1037,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7f307-39ce-488d-8b2e-112f0e94f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "c4897c6d-903a-4e9e-a19b-bfae7a4f01be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................CGACACGTCTTTAATGCAAAATTAACCTGA\n",
      "...................GCGACACGTCTTTAAAGCAAAATTAACCTG.\n",
      "...............TTGGGCGACACGTCTTTAAAGCAAAATTAA.....\n",
      "..............CTTGGGCGACACGTCTTTAAAGCAAAATTA......\n",
      "............CGCTTGGGCGACACGTCTTTAAAGCAAAAT........\n",
      "..........AGCGCTTGGGCGACACGTCTTTAAAGCAAA..........\n",
      "......ATGAAGCGCTTGGGGGACACGTCTTTAAAG..............\n",
      "......ATGAAGCGCTTGGGCGACACGTCTTCAAAG..............\n",
      "...CGCATTAAGCGCTTGGGCGACACGTCTTTA.................\n",
      "ACCCGCATCAAGCGCTTGGGCGACACGTCT....................\n",
      "..CCGCATGAAGCGCTTGGGCGACACGTCTTT..................\n",
      "...........GCGCAAGGGCGACACGTTTTAAAGCAAAAT.........\n",
      "ACCCCCATGAAGCGCTTGGGCGACACGTTT....................\n",
      ".CCCGCATGAATCGCTTGGGCGACACGTTTT...................\n",
      "..............CTTGGGCGACACGTTTTAATGCAAAATTAA......\n",
      "...............TTGGGCGACACGTTTTAAAGCAATATTAAC.....\n",
      "......ATGAAGCGCTTGGGCGACACATTTTAAAGC..............\n",
      "................TGGGCGACACGTTTTAAAGCAAAATGAACC....\n",
      "...CGCATGAAGCGCTTGGGCAACACGTTTTAA.................\n",
      "..CCGCATGAAGCGCTTGGGCGACACGTTTTA..................\n",
      "..CCGCATGAAGCGCTTGGGCGACACGTTTTA..................\n",
      "ACCCGCATGAAGCGCTTGGGCGACACGTTT....................\n",
      "..........AGCGCTTGGGCGACACGTTTTAAAGCAAAA..........\n",
      ".................GGGCGACACGTTTTAAAGCAAAATTAACCT...\n",
      ".....CATGAAGCGCTTGGGCGACACGTTTTAAAG...............\n",
      "\n",
      "ACCCGCATGAAGCGCTTGGGCGACACGTTTTAAAGCAAAATGAACCGAAA\n",
      "*****************************************x****xx*x\n",
      "ACCCGCATGAAGCGCTTGGGCGACACGTCTTTAAAGCAAAATTAACCTGA\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "which = 2\n",
    "def readstr(t):\n",
    "    t = t.detach().cpu().numpy()\n",
    "    assert len(t.shape) == 2, \"Need two dimensional input\"\n",
    "    output = []\n",
    "    for pos in range(t.shape[0]):\n",
    "        if t[pos, :].sum() == 0:\n",
    "            output.append(\".\")\n",
    "        else:\n",
    "            output.append(INDEX_TO_BASE[np.argmax(t[pos, :])])\n",
    "\n",
    "    return \"\".join(output)\n",
    "\n",
    "def to_pileup(data):\n",
    "    pileup = []\n",
    "    for i in range(data.shape[1]):\n",
    "        pileup.append(readstr(data[:, i, :]))\n",
    "    return \"\\n\".join(pileup)\n",
    "\n",
    "def predprobs(t):\n",
    "    t = t.detach().cpu().numpy()\n",
    "    output = []\n",
    "    for pos in range(t.shape[0]):\n",
    "        if t[pos, :].sum() == 0:\n",
    "            output.append(\".\")\n",
    "        else:\n",
    "            output.append(f\"{t[pos, np.argmax(t[pos, :])]:.1}f\")\n",
    "    return \"\".join(output)\n",
    "\n",
    "def correctstr(seq, predseq):\n",
    "    seq = \"\".join(INDEX_TO_BASE[b] for b in seq)\n",
    "    output = \"\".join('*' if a==b else 'x' for a,b in zip(seq, predseq))\n",
    "    return output\n",
    "    \n",
    "\n",
    "print(to_pileup(src[which, :, :, :]))\n",
    "\n",
    "print(\"\")\n",
    "predstr = readstr(seq1preds[which, :, :])\n",
    "print(predstr)\n",
    "print(correctstr(tgt_seq1[which, :], predstr))\n",
    "predstr = readstr(seq2preds[which, :, :])\n",
    "print(predstr)\n",
    "print(correctstr(tgt_seq2[which, :], predstr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "08ad12fc-70e1-438a-9e5d-f83bd3f836d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-512-95853493229a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_het_snv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAAAAAAAAAAAAAAA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pileup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "t = make_het_snv('AAAAAAAAAAAAAAAAAAAA', readlength=10, totreads=10, vaf=0.5, error_rate=0).transpose(0,1)\n",
    "print(to_pileup(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9081040-1d7b-43e4-a7f9-e4e750ce044c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "a63e9419-1419-48e3-8a3f-74fa75503064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3756, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(predictions.flatten(start_dim=0, end_dim=1), tgt.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865550bc-e3a5-4b29-8b96-b3844e6791e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8b47f-d66c-42eb-bee9-0a16617c1869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fade9-e74e-4d8c-956a-40103be54c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "9c7a64a7-c645-44e2-b067-56dccbec49c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 150])"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 149)\n",
    "z = torch.zeros(2,1)\n",
    "torch.cat((x,z), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e7588-b99d-41b9-b664-370eed0c69c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69528f15-52b5-4f58-af68-3b07995c6e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
