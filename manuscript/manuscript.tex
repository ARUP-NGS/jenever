\documentclass[]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{authblk}
\graphicspath{ {./images/} }
\linespread{1.15}
\textwidth=380pt


\title{Variant calling with transformers}
\author[1]{Brendan O'Fallon}
\author[1]{Ashini Bolia}
\author[1]{Jacob Durtschi}
\author[1]{Luobin Yang}

\affil[1]{ARUP Institute for Clinical and Experimental Pathology, Salt Lake City, UT}
\date{}
\begin{document}

\maketitle

\begin{abstract}
	Detection of germline variants in next-generation sequencing data is an essential element of modern genomics. Variant detection tools typically rely on a variety of statistical algorithms and heuristic techniques to identify variants. Here we describe a new approach that replaces the handcrafted statistical methods with a single, end-to-end deep learning model. Our model frames variant detection as a sequence-to-sequence modeling task, and employs a transformer-based architecture to translate alignment columns into two predicted haplotype sequences. We demonstrate that this method predicts variant genotypes accurately, phases nearby variants correctly, and has the ability to realign complex and ambiguous read mappings to produce accurate haplotype predictions. 

\end{abstract}



\section{Introduction}

Accurate reconstruction of the DNA sequence in a sample is a fundamental component of modern genomics analysis. Next Generation Sequencing (NGS) workflows typically begin by aligning sequenced fragments to a reference genome, optionally performing some alignment post-processing steps such as identification of duplicated fragments, and then identifying sequence variants relative to the reference genome. The variant identification step is challenging for many reasons, including technical artifacts in the sequencing process, improper alignments due to sequence homology or low sequence complexity, and the stochastic nature of the library preparation and amplification steps (Li 2014). 

All variant discovery tools must address two challenges. First, callers must identify potential  alleles in a region. Then, given a set of allele candidates, they must assess the likelihood of each candidate (or pairs of candidates in the diploid case), to determine which should be included in the caller output. Early callers, such as samtools / mpileup (Li et al. 2009) and the UnifiedGenotyper tool from the Genome Analysis ToolKit (GATK, De Pristo et al. 2011) rely on the read aligner to generate candidate allele candidates, and utilize ad-hoc heuristics and thresholds to determine likely alleles (Nielsen et al. 2011). Later tools (e.g. Poplin et al. 2018, Kim et al. 2018, Cooke et al. 2021) incorporated local re-assembly of reads in each region of interest, resulting in a significant improvement in the precision and specificity of variant calls. For instance, the HaplotypeCaller tool identifies candidate haplotypes by constructing de Bruijn graphs from k-mers present in the reads, and assesses haplotype likelihoods with a pair Hidden Markov Model (HMM). 

More recent tools have incorporated elements of deep learning into the allele likelihood calculation. DeepVariant (Poplin et al. 2018) builds on the HaplotypeCaller approach, but adds a Convolutional Neural Net (CNN) to classify variants as true or false positive detections. HELLO (Ramachandran et al. 2020), designed to work on hybrid short- and long-read datasets, employs a mixture-of-experts approach with separate 1-dimensional convolutions across the read and allele dimensions of the input. 

While replacing the statistical and heuristic components of the allele likelihood calculation with a deep learning model has resulted in improved specificity of variant callers, current tools continue to rely on complex, handcrafted statistical machinery to identify possible alleles. Here, we describe a new approach that replaces both the candidate allele generation and the likelihood calculation with a single, learned model. We recast variant detection as a sequence-to-sequence translation problem in which the input sequence is the series of bases aligning to a single genomic location, and the output sequences are the two predicted haplotypes. The sequence-to-sequence translation is performed by a transformer-based deep neural network (Vaswani et al. 2017). We demonstrate that this approach identifies real genomic variants with sensitivity similar to current top-performing callers, albeit with lower specificity. 

While transformers have not been explored for variant detection, a model similar to ours was proposed by Baid et al. (2021) for generation of accurate consensus reads from PacBio data. The Baid model (`DeepConsensus') used a network architecture similar to ours, but included an extra token representing a gap between the aligned sequences, and a novel loss function that accounted for gaps between the predicted and true sequence in a region. In contrast we use a simple cross-entropy loss function, and do not introduce gaps in the aligned sequences compared to the reference. 

\section{Methods}

\subsection{Model architecture}

Our model consists of a transformer-based encoder and simple, fully connected decoder that produces two output sequences, one for each predicted haplotype. The encoder component is an unmodified transformer with GeLU activations as implemented in PyTorch 1.10 (Paszke et al. 2019). Input tokens are the collection of bases that align to a given reference position across reads, with some modifications described below. We add an additional fully connected layer prior to the transformer encoders which embeds the encoded basecalls in $d$ dimensions, where $d=12$ for the analyses here. The embedded basecalls are 'flattened' along the read dimension, producing an input token with size $dr$ where $r$ is the number of reads. Instead of the typical 1-dimensional positional encoding, we employed a 2-dimensional encoding, enabling the model to retain information about which read contained a given base across input tokens. 

The decoder consists of a single fully-connected layer followed by two additional fully connected components that each generate a single haplotype. Predictions are discrete probability distributions over the four possible bases at each predicted output position, produced with a softmax function over the raw outputs. The decoder is of fixed size, and each predicted haplotype contains the same number of predicted bases as the number of positions $g$ in the input. 


\subsection{NGS data}

We obtained training data from 17 whole genomes sequenced from 5 Genome-in-a-Bottle cell lines. Eight samples were prepared with Illumina Nextera DNA Flex kit and the remainder were prepared with the Illumina TruSeq PCR-free kit. All samples were sequenced on an Illumina NovaSeq 6000 instrument in 2x150 mode, to an approximate read depth of 50. After conversion to fastq, the sequenced reads were aligned to human reference genome GRCh37 with the GEM-mapper (v3, Marco-Sola et al. 2012) and were sorted and converted to CRAM format with samtools version 1.9 (Li et al. 2009). No additional refinements, such as duplicate read marking, base-quality score recalibration, or indel realignment were performed.

\subsection{Training data}

Training tensors were generated by selecting regions 150bp in width from a list of preselected regions, in a manner described below. For each region, all reads overlapping the window were obtained from the corresponding BAM/ CRAM file. If more than a specified maximum number of reads were found (100 for all analyses here), then reads were downsampled to the desired size.  Reads were sorted by the reference coordinate of the first aligned base. For each aligned base in the selected reads nine features were encoded; the first four were the one-hot encoded base call, followed by base quality, two flags indicating if base `consumed' reference base (i.e. was not an insertion) or consumed a sequence read base (was not a deletion), and additional flags indicating sequence read direction and clipping status.  No 'gap' tokens or other special handling was performed for insertions or deletions. In addition to sequenced reads, the first row in each encoded region was the reference sequence. For this special row we inserted a base quality of 100 for every position and did not set any of the other flags. Resulting tensors had dimension $[150, 100, 9]$, where the indices are for the genomic position, read, and feature respectively.  

Target / label haplotype sequences were produced by obtaining truth variants from the Genome-in-a-Bottle VCF files for each sample and inserting the variants into the reference sequence. Two sequences were generated for each region, one representing each haplotype. In regions where phasing of the variants was ambiguous, the reads in the sequenced sample were examined to determine phase status. Briefly, all possible genotypes (pairs of haplotype sequences) were generated and reads were aligned via Smith-Waterman to the possible haplotypes, and the highest scoring genotypes selected as the most likely phasing. This phasing procedure procedure was only attempted for variants less than 100bp apart, otherwise the region was discarded.

To select regions to include for training data, we developed a scheme to sample regions in a biased manner, prioritizing regions containing variants and, especially, regions with multiple or complex variants. Regions of the reference genome overlapping the high-confidence regions from Genome-in-a-Bottle were subdivided into 150bp nonoverlapping windows, and these regions labelled according to the presence of variants. Separate labels were generated for regions conataining a single SNV, deletion, or insertion, as well as regions containing multiple insertion-deletions, or those containing variants intersecting  low-complexity regions. We additionally included `true negative' regions where no known variant was present.  For all analyses described here, we obtain training data only from the human autosomes 1-20, and hold out chromosomes 21 and 22 for model evaluation.  We examine three different sizes of training data sets, with 5.5M, 10.4M, and 20.4M examples. 

\subsection{Training procedure}


Models were implemented in Pytorch (v1.10, Paszke et al 2019). Models were trained for 25 epochs unless noted otherwise, using the Adam optimizer and a learning rate of $5e-5$. 

\subsection{Loss function}

We use a standard cross-entropy loss function to compare predicted haplotypes to known haplotype sequences for each region, and simply compare each prediction at window index (position) $i$ to the true base at index $i$. A complexity arises due to ambiguity regarding which haplotype should contain a variant. The two haplotypes present in a sample have no inherent order. In training data variants are assigned arbitrarily to haplotypes, and this randomness in haplotype assignment means the model cannot learn to predict which haplotype should contain a given variant. To combat this ambiguity, we calculate loss in both possible configurations - predicted haplotype 0 with training haplotype 0 and 1 with 1, as well as predicted haplotype 0 with training haplotype 1 and 1 with 0. We select the configuration with the lowest loss and backpropogate gradients only for that configuration. 



\subsection{Variant detection}

Given an alignment file in BAM or CRAM format, we first identify regions where a potential variant might exist. Any genomic position in which at least three reads contain a base that differs from the reference or an indel are flagged as potentially containing a variant. Positions closer than 100bp are merged into a single region. 


Given a region containing suspected variants, we perform multiple overlapping forward passes of the model with step size $k$, where $k=50$ for the results reported here. On each forward pass the model produces two predicted haplotypes by taking the base with the high predicted probability at each position. Each haplotype is aligned via Smith-Waterman to the reference sequence, and any mismatching positions are converted to variant calls. For each variant we record the number of windows in which each variant was detected, the number of variants in cis and trans, and the mean probability of the variant bases, and the position of the variant within each window.   


\subsection{Variant quality calculation}

The above variant detection procedure has two shortcomings. First, if every potential variant is emitted, then specificity is poor. Second, the model does not innately produce well calibrated variant quality scores. To address these shortcomings we introduce a post-hoc random forest classifier that we train to discriminate true and false-positive variant calls (see table X for features).  The resulting score is used as a final variant quality score suitable for tuning the tradeoff between sensitivity and specificity. 

The random forest classifier is trained by calling variants on selected regions from autosomes 1-4 totalling approximately 120Mb. True and false positive variant calls were identified with the \textit{vcfeval} tool (Cleary et al. 2015). We used the scikit-learn implementation of the random forest with 100 trees, a maximum tree depth of 25, and 'balanced' class weighting option.  


\section{Results}

\subsection{Model size and training data experiments}

We explore the effects of model size and training data size on validation loss and variant detection accuracy. We evaluate three model sizes and two sets of training data.

\begin{center}
	\begin{tabular}{ |c|c|c|c|c| }
	 Model name & Encoder layers & Attention heads & Hidden dimension & Embedding dimension \\ 
	\hline
	 5m & 4 & 4 & 200 & 600 \\ 
	 10m & 6 & 6 & 250 & 400 \\ 
	 25m & 8 & 8 & 400 & 800 \\ 
	 \hline
	\end{tabular}
\end{center}



\subsection{Genotyping \& Phasing}

To check the accuracy of predicted genotypes and phasing of variants we compared calls to the known genotype and, when available, phase from Genome-in-a-Bottle (GIAB). Approximately 99.5\% of homozygous  and 99.0\% of heterozygous calls matched the true genotype, indicating that our model learns to construct both haplotypes accurately.  For phasing accuracy, we identified pairs of heterozygous variants less than 100 base pairs apart and compared their phasing predictions with the known phasing information from GIAB. The phasing information in GIAB samples is only available for HG001, HG002 and HG005 cell lines, so our analysis is restricted to only those samples. Approximately 99.4\% of predicted variant pairs had phase that matched the true phase from GIAB. 

Accurate phase prediction requires that information regarding which reads support a given haplotype is propogated among input tokens (genomic positions). Our model's relatively high phasing accuracy suggests that 


\subsection{Complex regions}
 While many genomic variants are trivial to identify by examination of mapped reads, some regions require a more sophisticated reassembly to identify the true haplotype. We examine the ability of our model to perform this more complicated reconstruction by identifying real variants in regions containing multiple conflicting read mappings or extensive read soft-clipping. 
 
 To identify variants requiring complex reconstruction, we first obtain all indel variants from Genome-in-a-Bottle greater than 4 bp from the validation regions on chromosomes 21 and 22. For each variant, we examine the reads in the alignment file that overlap the variant position, and flag any with with more than 4 distinct indel start sites or at least 20\% reads with more than 10bp softclipped as requiring 'complex' reconstruction. These variants are moved to a separate truth set. After running our variant calling procedure on the alignment file, we compute the fraction of variants from the truth set that were identified by our model. This procedure was repeated for all 17 samples in our data set. 

 Our model is able to reconstruct the correct haplotypes for ~90.8\% (mid 50\% 86.4-95.2) of these variants, somewhat lower than HaplotypeCaller accuracy of ~95.8\% (mid 50\% 91.0-100.0).  Although model performance does not match current state-of-the-art callers, it nonetheless is able to reconstruct the true haplotype in most cases. Overall, these results indicate that the model learns a reconstruction procedure more nuanced than a simple column-by-column examination of reads, 


\subsection{Use of local context}
 - Also ambiguous, but anecdotally when looking at variant calls, it seems apparent that variants that otherwise look real have lower quality scores when there's a lot of junk around. That's good, since such variants are more likely To
 be false positives, and that means the model is to some extent looking at local context to modify prediction accuracy. Which is cool. 



 \subsection{Variant detection accuracy}

 - Tabulate Hap.py results across a few common stratifications, compare to other callers

\subsection{Ablation experiments}
 
 Ablate the 2D positional encoding.

 Ablate reference as read 0 
 
 


\section{Discussion}

We describe a new approach to the problem of detecting sequence variants in next-generation sequencing (NGS) data based on a single, end-to-end deep learning model. Our approach envisions variant detection as a sequence-to-sequence modeling problem, akin to language translation, and leverages the successful transformer architecture to accomplish this task. In contrast to other variant detection methods (...), our approach does not rely on handcrafted statistical techniques such as de Bruijn graphs, hidden Markov models, or heuristic thresholding and instead learns to construct accurate haplotypes directly from aligned NGS reads. 
 
Our analysis demonstrates that the model learns many features of modern, state of the art variant callers. For instance, our model learns to reconstruct large, complex variants in the presence of ambiguous mapping and extensive soft clipping. In addition, the model learns to employ local context and read-specific features to predict phase and genotype accurately, and pairs of variants are phased correctly in ~99\% of cases where variants are within 100bp.   

In this work we have used a standard cross-entropy loss function that simply compares each prediction at base $i$ to the label at base $i$. While training with this loss yields accurate results, it has two significant shortcomings. First, the impact of an insertion / deletion (indel) error depends on its position in the region, with indels at lower indices leading to a greater number of mismatches and high loss compared to indels at higher indices. Secondly, indel errors ar punished more severely than similar SNV errors. We hypothesize the second fact explains the lower performance of our model on SNV calls compared to indels. Alternative, alignment-based loss functions such as those described by Baid et al. (2021) and Petti et al. (2021) may provide a path forward, however the Petti implementation lead to lower sensitivity in our experiments.  


For this work we have employed an unmodified transformer model with a very simple decoder consisting of just two fully connected layers, and we leave to future work exploration of the many transformer variations proposed in recent years (e.g. Dosovitskiy 2018, Fedus et al. 2021, Liu et al 2021, Wu et al. 2021). Our simple decoder only predicts haplotypes that are equal in length to the number of input tokens (genomic positions), but a natural improvement would be to add a more sophisticated decoder capable of producing a variable length sequence to handle larger insertion and deletion events.  In addition, newer transformer models that avoid the $O(n^2)$ scaling with the number of input tokens may be able to handle longer input sequence lengths, and therefore may be able to detect larger variants. 

\section{Availability}
 
 Source code for is available via git at https://github.com/ARUP-NGS/somewhere
 
\section{References}

\vspace{8pt}
Baid, Gunjan, et al. "DeepConsensus: Gap-Aware Sequence Transformers for Sequence Correction." bioRxiv (2021).

\vspace{8pt}
Cleary, John G., et al. "Comparing variant call files for performance benchmarking of next-generation sequencing variant calling pipelines." BioRxiv (2015): 023754.

\vspace{8pt}
Cooke, Daniel P., David C. Wedge, and Gerton Lunter. "A unified haplotype-based method for accurate and comprehensive variant calling." Nature biotechnology 39.7 (2021): 885-892.

\vspace{8pt}
DePristo, Mark A., et al. "A framework for variation discovery and genotyping using next-generation DNA sequencing data." Nature genetics 43.5 (2011): 491-498.
 
\vspace{8pt}
Dosovitskiy, Alexey, et al. "An image is worth 16x16 words: Transformers for image recognition at scale." arXiv preprint arXiv:2010.11929 (2020).

\vspace{8pt}
Fedus, William, Barret Zoph, and Noam Shazeer. "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity." arXiv preprint arXiv:2101.03961 (2021).

\vspace{8pt}
Kim, Sangtae, et al. "Strelka2: fast and accurate calling of germline and somatic variants." Nature methods 15.8 (2018): 591-594.

\vspace{8pt}
Li, Heng. "Toward better understanding of artifacts in variant calling from high-coverage samples." Bioinformatics 30.20 (2014): 2843-2851.

\vspace{8pt}
Li, Heng, et al. "The sequence alignment/map format and SAMtools." Bioinformatics 25.16 (2009): 
2078-2079.


\vspace{8pt}
Li, Heng, and Richard Durbin. "Fast and accurate short read alignment with Burrows–Wheeler transform." Bioinformatics 25.14 (2009): 1754-1760.

\vspace{8pt}
Liu, Ze, et al. "Swin transformer: Hierarchical vision transformer using shifted windows." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.

\vspace{8pt}
Marco-Sola S., Sammeth M., Guigó R., Ribeca P. "The GEM mapper: fast, accurate and versatile alignment by filtration". Nat Methods. (2012);9(12):1185-1188. doi:10.1038/nmeth.2221

\vspace{8pt}
Nielsen, Rasmus, et al. "Genotype and SNP calling from next-generation sequencing data." Nature Reviews Genetics 12.6 (2011): 443-451.

\vspace{8pt}
Paszke, A., et al. "PyTorch: An Imperative Style, High-Performance Deep Learning Library." In Advances in Neural Information Processing Systems 32 (2019):8024–8035. Curran Associates, Inc. Retrieved from http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf

\vspace{8pt}
Petti, Samantha, et al. "End-to-end learning of multiple sequence alignments with differentiable Smith-Waterman." BioRxiv (2021).

\vspace{8pt}
Poplin, Ryan, et al. "A universal SNP and small-indel variant caller using deep neural networks." Nature biotechnology 36.10 (2018): 983-987.

\vspace{8pt}
Poplin, Ryan, et al. "Scaling accurate genetic variant discovery to tens of thousands of samples." BioRxiv (2018): 201178.

\vspace{8pt}
Ramachandran, Anand, et al. "HELLO: A hybrid variant calling approach." bioRxiv (2020).
 

\vspace{8pt}
Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems 30 (2017).


\vspace{8pt}
Wu, Chuhan, et al. "Fastformer: Additive attention can be all you need." arXiv preprint arXiv:2108.09084 (2021).

\end{document}


